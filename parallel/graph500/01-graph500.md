# Building a Raspberry Pi Cluster




# Running the Graph 500 Benchmark

<img src="https://www.alcf.anl.gov/files/field/image/graph500-logo.jpg" align="lefgt" width="600" height="400">

#### What is Graph 500?


[Graph 500](http://www.graph500.org) is a relatively new benchmark meant to represent data intensive workloads in the fields of Cybersecurity, Medical Informatics, Data Enrichment, Social Networks, and Symbolic Networks. 

<img src="http://corte.si/%2Fposts/privacy/neighbourhoods-of-trust/images/full.png" align="lefgt" width="600" height="600">

Graph algorithms are a core part of many analytics workloads. The argument by over 50 international HPC experts is that a new set of benchmarks is needed in order to guide the design of hardware architectures and software systems intended to support such applications and to help procurements. The hope is that Graph 500 can rise to that challenge and become a compliment to the well known [Top 500 List](http://www.top500.org) which runs a benchmark called HPL (High Performance LINPACK).

On the Graph 500 website, a benchmark specification is provided. Problem classes ranging from toy (level 10) on up to huge (level 15) are outlined. We are hoping that when all 24 of the Raspberry Pis (along with a few extra) are connected together, we ***might*** be able to run the toy class of the problem.

The benchmark is measured in GTEPS (Giga - Transversed Edges Per Second) and by the number of vertices (given by 2^(SCALE)).

With a total of 32 Pis with 4 cores each, we can run efficiently a total of 128 MPI processes. The benchmark will be started towards the end of the day and it will be run on increasing problem scales until we either run out of time or we run out of memory!


## Challenge

1. Try for a spot on the November 2015 list -- and, if we are lucky, above at least one other entry!
2. Over the next six days, work up to the toy class which consists of 67,108,864 vertices taking up over 17 GB RAM across all 32 Raspberry Pis.
